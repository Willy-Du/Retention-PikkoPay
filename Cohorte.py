import pandas as pd
import numpy as np
import os
import streamlit as st
import plotly.graph_objects as go
import matplotlib.cm as cm
import matplotlib
from datetime import datetime, timedelta
from collections import defaultdict
import plotly.express as px 
from pymongo import MongoClient
from bson import ObjectId
from dotenv import load_dotenv


load_dotenv()
MONGO_URI = os.getenv("MONGO_URI")
# VÃ©rifier si la connexion MongoDB est dÃ©jÃ  stockÃ©e dans `st.session_state`
if "mongo_client" not in st.session_state:
    st.session_state.mongo_client = MongoClient(MONGO_URI)
    st.session_state.db = st.session_state.mongo_client["storesDatabase"]
    st.session_state.users_collection = st.session_state.db["usertests"]
    st.session_state.orders_collection = st.session_state.db["ordertests"]

# VÃ©rifier que la connexion a bien Ã©tÃ© stockÃ©e
users_collection = st.session_state.users_collection
orders_collection = st.session_state.orders_collection

# DÃ©finition des magasins avec leur date de lancement
store_mapping = {
    "65e6388eb6667e3400b5b8d8": {"name": "SupermarchÃ© Match", "launch_date": datetime(2024, 6, 10)},
    "65d3631ff2cd066ab75434fa": {"name": "IntermarchÃ© Saint Julien", "launch_date": datetime(2024, 4, 1)},
    "662bb3234c362c6e79e27020": {"name": "Netto Troyes", "launch_date": datetime(2024, 5, 6)},
    "64e48f4697303382f745cb11": {"name": "Carrefour Contact BuchÃ¨res", "launch_date": datetime(2023, 11, 5)},
    "65ce4e565a9ffc7e5fe298bb": {"name": "Carrefour Market Romilly", "launch_date": datetime(2024, 2, 16)},
    "65b8bde65a0ef81ff30473bf": {"name": "Jils Food", "launch_date": datetime(2024, 2, 12)},
    "67a8fef293a9fcb4dec991b4": {"name": "IntermarchÃ© EXPRESS Clamart", "launch_date": datetime(2025, 3, 3)}
}

payment_mapping = {
    "Tous": "Tous",
    "apple-pay": "Apple Pay",
    "apple_pay": "Apple Pay",
    "applepay": "Apple Pay",
    "cb": "CB",
    "conecs": "Conecs",
    "edenred": "Edenred",
    "googlepay": "Google Pay",
    "https://google.com/pay": "Google Pay"
}

# ğŸ“Œ Connexion MongoDB
client = MongoClient(MONGO_URI)
db = client['storesDatabase']
users_collection = db['usertests']
orders_collection = db['ordertests']

# ğŸ“Œ Ajout du menu de navigation dans la barre latÃ©rale
st.sidebar.title("ğŸ“Š Dashboard de suivi")

# SÃ©lection du magasin (obligatoire)
displayed_store_id = st.sidebar.selectbox(
    "SÃ©lectionnez un magasin :",
    options=list(store_mapping.keys()),
    format_func=lambda x: store_mapping[x]["name"]
)

date_end = datetime.now()
date_start = store_mapping[displayed_store_id]["launch_date"]
store_filter = ObjectId(displayed_store_id)

unique_payments = st.session_state.users_collection.distinct(
    "receipt.paymentMethod",
    {
        "receipt.storeId": store_filter,
        "receipt.isPaid": True,
        "receipt.paidAt": {"$gte": date_start, "$lte": date_end}
    }
)

normalized_payments = {payment_mapping.get(p, p) for p in unique_payments}
normalized_payments.add("Tous")
payment_options = ["Tous"] + sorted([p for p in normalized_payments if p != "Tous"])

selected_payment_method = st.sidebar.selectbox(
    "SÃ©lectionnez un mode de paiement :",
    options=payment_options,
    index=0  
)

# PrÃ©paration du filtre de base pour les pipelines
base_filter = {
    "receipt.isPaid": True,
    "receipt.storeId": store_filter,
    "receipt.paidAt": {"$gte": date_start, "$lte": date_end}
}


# Dictionnaire pour associer la mÃ©thode normalisÃ©e Ã  toutes ses variantes rÃ©elles possibles
payment_variants = {
    "Apple Pay": ["apple-pay", "apple_pay", "applepay"],
    "Google Pay": ["googlepay", "https://google.com/pay"],
    "CB": ["cb", "CB"],
    "Conecs": ["conecs", "Conecs"],
    "Edenred": ["edenred", "Edenred"]
}
payment_filter = {}
if selected_payment_method != "Tous":
    if selected_payment_method in payment_variants:
        variants = payment_variants[selected_payment_method]
    else:
        variants = [selected_payment_method]
    payment_filter = {"receipt.paymentMethod": {"$in": variants}}

match_filter = {**base_filter, **payment_filter}

page = st.sidebar.radio(
    "Choisissez une section :", 
    ["RÃ©tention", "Acquisition", "Active Users", "Bug Report"]
)

# ========================
# Partie RÃ©tention
# ========================
if page == "RÃ©tention":

    if selected_payment_method == "Tous":
        # For "Tous" (All), use the original pipeline
        pipeline_new_users_week = [
            {"$unwind": "$receipt"},
            {"$match": base_filter},
            {"$sort": {"receipt.paidAt": 1}},
            {"$group": {
                "_id": "$_id",
                "firstPaidAt": {"$first": "$receipt.paidAt"}
            }},
            {"$addFields": {
                "firstPaidWeek": {"$isoWeek": "$firstPaidAt"},
                "firstPaidYear": {"$isoWeekYear": "$firstPaidAt"}
            }},
            {"$group": {
                "_id": {"year": "$firstPaidYear", "week": "$firstPaidWeek"},
                "new_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_new_users": {"$size": "$new_users"},
                "new_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.week": 1}}
        ]
    else:
        # For specific payment methods, use a two-stage approach
        pipeline_new_users_week = [
            # Stage 1: Find users who have used the selected payment method
            {"$unwind": "$receipt"},
            {"$match": match_filter},
            {"$group": {"_id": "$_id"}},
            
            # Stage 2: For these users, find their first payment date (regardless of method)
            {"$lookup": {
                "from": "usertests",
                "localField": "_id",
                "foreignField": "_id",
                "as": "user_data"
            }},
            {"$unwind": "$user_data"},
            {"$unwind": "$user_data.receipt"},
            {"$match": {"user_data.receipt.isPaid": True, "user_data.receipt.storeId": store_filter}},
            {"$sort": {"user_data.receipt.paidAt": 1}},
            {"$group": {
                "_id": "$_id",
                "firstPaidAt": {"$first": "$user_data.receipt.paidAt"}
            }},
            {"$addFields": {
                "firstPaidWeek": {"$isoWeek": "$firstPaidAt"},
                "firstPaidYear": {"$isoWeekYear": "$firstPaidAt"}
            }},
            {"$group": {
                "_id": {"year": "$firstPaidYear", "week": "$firstPaidWeek"},
                "new_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_new_users": {"$size": "$new_users"},
                "new_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.week": 1}}
        ]

    # Liste des testeurs Ã  exclure
    testers_to_exclude = [
        ObjectId("66df2f59c1271156d5468044"),
        ObjectId("670f97d3f38642c54d678d26"),
        ObjectId("65c65360b03953a598253426"),
        ObjectId("65bcb0e43956788471c88e31")
    ]

    # Use the same approach for active users
    if selected_payment_method == "Tous":
        pipeline_active_users_week = [
            {"$unwind": "$receipt"},
            {"$match": {**base_filter, "_id": {"$nin": testers_to_exclude}}},
            {"$addFields": {
                "paymentWeek": {"$isoWeek": "$receipt.paidAt"},
                "paymentYear": {"$isoWeekYear": "$receipt.paidAt"}
            }},
            {"$group": {
                "_id": {"year": "$paymentYear", "week": "$paymentWeek"},
                "active_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_active_users": {"$size": "$active_users"},
                "active_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.week": 1}}
        ]
    else:
        pipeline_active_users_week = [
            {"$unwind": "$receipt"},
            {"$match": {**match_filter, "_id": {"$nin": testers_to_exclude}}},
            {"$addFields": {
                "paymentWeek": {"$isoWeek": "$receipt.paidAt"},
                "paymentYear": {"$isoWeekYear": "$receipt.paidAt"}
            }},
            {"$group": {
                "_id": {"year": "$paymentYear", "week": "$paymentWeek"},
                "active_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_active_users": {"$size": "$active_users"},
                "active_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.week": 1}}
        ]

    # ExÃ©cuter les requÃªtes MongoDB
    cursor_new_users_week = st.session_state.users_collection.aggregate(pipeline_new_users_week)
    cursor_active_users_week = st.session_state.users_collection.aggregate(pipeline_active_users_week)

    data_new_users_week = list(cursor_new_users_week)
    data_active_users_week = list(cursor_active_users_week)

    # VÃ©rification des donnÃ©es
    if not data_new_users_week or not data_active_users_week:
        st.error("âŒ Aucune donnÃ©e trouvÃ©e ! VÃ©rifiez la structure de votre base MongoDB.")
        st.stop()

    # Transformation en DataFrame
    df_new_users_week = pd.DataFrame(data_new_users_week)
    df_active_users_week = pd.DataFrame(data_active_users_week)

    # Extraction des annÃ©es et semaines (pour les donnÃ©es hebdomadaires)
    df_new_users_week['year'] = df_new_users_week['_id'].apply(lambda x: x['year'])
    df_new_users_week['week'] = df_new_users_week['_id'].apply(lambda x: x['week'])
    df_active_users_week['year'] = df_active_users_week['_id'].apply(lambda x: x['year'])
    df_active_users_week['week'] = df_active_users_week['_id'].apply(lambda x: x['week'])

    # GÃ©nÃ©rer la colonne "dÃ©but de semaine" (pour la partie hebdomadaire)
    df_new_users_week['week_start'] = df_new_users_week.apply(lambda x: datetime.fromisocalendar(x['year'], x['week'], 1), axis=1)
    df_active_users_week['week_start'] = df_active_users_week.apply(lambda x: datetime.fromisocalendar(x['year'], x['week'], 1), axis=1)

    # Convertir ObjectId en str pour faciliter la manipulation
    df_new_users_week['new_users'] = df_new_users_week['new_users'].apply(lambda users: set(str(u) for u in users) if users else set())
    df_active_users_week['active_users'] = df_active_users_week['active_users'].apply(lambda users: set(str(u) for u in users) if users else set())

    # Trier et indexer par "week_start"
    df_new_users_week = df_new_users_week.sort_values(by='week_start').set_index('week_start')
    df_active_users_week = df_active_users_week.sort_values(by='week_start').set_index('week_start')

    # GÃ©nÃ©rer la liste complÃ¨te des semaines (plage hebdomadaire)
    all_weeks_range = pd.date_range(start=date_start, end=datetime.now(), freq='W-MON')

    # CrÃ©er un DataFrame pour toutes les semaines avec la colonne total_new_users initialisÃ©e Ã  0
    all_weeks_df = pd.DataFrame(index=all_weeks_range)
    all_weeks_df['total_new_users'] = 0

    # Mettre Ã  jour les valeurs pour les semaines disposant de donnÃ©es
    for idx in df_new_users_week.index:
        if idx in all_weeks_df.index:
            all_weeks_df.loc[idx, 'total_new_users'] = df_new_users_week.loc[idx, 'total_new_users']

# ====================================
# Calcul de la rÃ©tention hebdomadaire
# ====================================

    if df_new_users_week.empty:
        st.warning("Aucun nouvel utilisateur trouvÃ© pour ce mode de paiement.")
        df_numeric_week = pd.DataFrame(columns=['total_new_users', '+0'])
        df_percentage_week = pd.DataFrame(columns=['total_new_users', '+0'])
    else:
        # ====================================
        # Calcul de la rÃ©tention hebdomadaire
        # ====================================
        
        # Dictionnaire pour stocker la rÃ©tention par cohorte
        week_retention = {}
        
        # Combiner les indices de all_weeks_range et df_new_users_week pour Ã©viter les KeyError
        all_cohort_dates = set(all_weeks_range) | set(df_new_users_week.index)
        
        # Pour chaque date de la plage complÃ¨te, initialiser la colonne "+0" Ã  0
        for idx in all_cohort_dates:
            week_retention[idx] = {"+0": 0}
        
        # Pour chaque cohorte (dÃ©terminÃ©e dans df_new_users_week), calculer la rÃ©tention
        for index, row in df_new_users_week.iterrows():
            new_user_set = row['new_users']
            week_retention[index]["+0"] = len(new_user_set)
            
            # S'il n'y a pas de nouveaux utilisateurs, on passe Ã  la cohorte suivante
            if not new_user_set:
                continue
        
            # SÃ©lectionner les semaines actives postÃ©rieures Ã  la date de cohorte
            if not df_active_users_week.empty:
                future_weeks = df_active_users_week.loc[df_active_users_week.index > index]
                for future_index, future_row in future_weeks.iterrows():
                    # Calcul du dÃ©calage rÃ©el en semaines
                    week_diff = (future_index - index).days // 7
                    future_users = future_row['active_users']
                    retained_users = len(new_user_set.intersection(future_users)) if isinstance(future_users, set) else 0
                    week_retention[index][f"+{week_diff}"] = retained_users
        
        # Conversion du dictionnaire en DataFrame
        df_retention_week = pd.DataFrame.from_dict(week_retention, orient='index')
        
        # DÃ©finir la date actuelle et le dÃ©but de la semaine courante
        current_date = datetime.now()
        current_week_start = datetime.fromisocalendar(current_date.year, current_date.isocalendar()[1], 1)
        
        # Calculer l'horizon global : pour chaque cohorte, le nombre maximal de semaines possibles
        global_max = 0
        for index in df_retention_week.index:
            # Calcul du nombre de semaines Ã©coulÃ©es entre la cohorte et la semaine courante
            possible = (current_week_start - index).days // 7
            if possible > global_max:
                global_max = possible
        
        # Pour chaque cohorte, s'assurer que les colonnes de "+0" jusqu'Ã  "+global_max" existent
        # et appliquer la logique suivante :
        # - Si la date (cohorte + N semaines) est dans le futur ( > current_week_start), la valeur doit rester None (NaN)
        # - Sinon, si aucune valeur n'existe, on remplit avec 0.
        for index, row in df_retention_week.iterrows():
            for week_diff in range(global_max + 1):
                col_name = f"+{week_diff}"
                future_week = index + pd.Timedelta(weeks=week_diff)
                if future_week > current_week_start:
                    df_retention_week.at[index, col_name] = None
                else:
                    # S'il n'existe pas encore ou si la valeur est NaN, on met 0
                    if col_name not in df_retention_week.columns or pd.isna(row.get(col_name, None)):
                        df_retention_week.at[index, col_name] = 0
        
        # CrÃ©er un DataFrame pour toutes les semaines avec la colonne total_new_users initialisÃ©e Ã  0
        all_weeks_df = pd.DataFrame(index=sorted(all_cohort_dates))
        all_weeks_df['total_new_users'] = 0
        
        # Mettre Ã  jour les valeurs pour les semaines disposant de donnÃ©es
        for idx in df_new_users_week.index:
            if idx in all_weeks_df.index:
                all_weeks_df.loc[idx, 'total_new_users'] = df_new_users_week.loc[idx, 'total_new_users']
        
        # ========================================
        # Fusion avec le DataFrame de toutes les semaines
        # ========================================
        df_numeric_week = all_weeks_df.merge(df_retention_week, left_index=True, right_index=True, how='left')
        
        # ======================================================
        # RÃ©ordonner les colonnes de rÃ©tention dans l'ordre croissant
        # ======================================================
        
        retention_cols = sorted(
            [col for col in df_numeric_week.columns if col.startswith("+")],
            key=lambda x: int(x.replace("+", ""))
        )
        other_cols = [col for col in df_numeric_week.columns if not col.startswith("+")]
        ordered_cols = other_cols + retention_cols
        df_numeric_week = df_numeric_week[ordered_cols]
        
        # CrÃ©ation d'une copie pour les pourcentages (hebdomadaire)
        df_percentage_week = df_numeric_week.copy()
        for col in df_percentage_week.columns:
            if col.startswith("+") and col != "+0":
                mask = (df_percentage_week["+0"] > 0) & (df_percentage_week[col].notna())
                df_percentage_week.loc[mask, col] = (df_percentage_week.loc[mask, col] / df_percentage_week.loc[mask, "+0"] * 100).round(1)
        df_percentage_week["+0"] = df_percentage_week["+0"].apply(lambda x: 100 if x > 0 else 0)

    # Fonction de dÃ©gradÃ© pour le style (hebdomadaire)
    def apply_red_gradient_with_future(val):
        if pd.isna(val):
            return 'background-color: #f0f0f0; color: #f0f0f0;'
        elif pd.notna(val):
            intensity = int(255 * ((1 - val / 100) ** 3))
            return f'background-color: rgba(255, {intensity}, {intensity}, 1); color: black;'
        return ''

    # Afficher les tableaux avec Streamlit (pour les donnÃ©es hebdomadaires)
    st.title("Partie RÃ©tention - Analyse Hebdomadaire")
    st.header("ğŸ“… Tableau des cohortes hebdomadaires (valeurs numÃ©riques)")
    st.dataframe(df_numeric_week)
    st.subheader("ğŸ“Š Tableau des cohortes hebdomadaires (%)")
    st.dataframe(df_percentage_week.style.applymap(apply_red_gradient_with_future, subset=[col for col in df_percentage_week.columns if col.startswith("+")]))

    # Calcul de la diagonale pour la semaine cible

    today = pd.Timestamp.today()
    # Calcul du dÃ©but de la semaine (lundi) et normalisation Ã  minuit
    target_week = (today - pd.Timedelta(days=today.weekday())).normalize()

    # Si l'index de df_active_users_week est un PeriodIndex, convertir target_week en pÃ©riode
    if isinstance(df_active_users_week.index, pd.PeriodIndex):
        target_week = pd.Period(target_week, freq='W-MON')

    diagonal_values = []
    for cohort_date, row in df_numeric_week.iterrows():
        # On ne considÃ¨re que les cohortes antÃ©rieures ou Ã©gales Ã  la semaine cible
        if cohort_date > target_week:
            continue

        # Calcul de l'offset en semaines entre la cohorte et la semaine cible
        offset = (target_week - cohort_date).days // 7
        col_name = f"+{offset}"
        
        # Si la colonne existe et contient une valeur (pas NaN)
        if col_name in row.index and pd.notna(row[col_name]):
            diagonal_values.append(row[col_name])
        else:
            st.write(f"âš ï¸ La colonne {col_name} est absente ou NaN pour la cohorte {cohort_date}")

    diagonal_sum = sum(diagonal_values)

    # RÃ©cupÃ©ration du nombre d'utilisateurs actifs uniques dans la semaine cible
    if target_week in df_active_users_week.index:
        active_users_data = df_active_users_week.loc[target_week, 'active_users']
        # S'il s'agit d'une liste ou d'un ensemble, on compte le nombre d'Ã©lÃ©ments
        if isinstance(active_users_data, (list, tuple, set)):
            unique_users_target = len(active_users_data)
        else:
            # Sinon, on suppose que la valeur est dÃ©jÃ  un nombre
            unique_users_target = active_users_data
    else:
        unique_users_target = 0

    st.write(f"Somme de la diagonale (hebdomadaire): {diagonal_sum}")
    st.write(f"Utilisateurs uniques de la semaine cible (hebdomadaire): {unique_users_target}")

    st.header("ğŸ“ˆ Ã‰volution du pourcentage d'utilisateurs par cohorte (hebdomadaire)")

    # PrÃ©parer les donnÃ©es pour le graphique : on utilise df_percentage_week et on retire Ã©ventuellement la colonne 'total_new_users'
    df_pct = df_percentage_week.copy()
    if 'total_new_users' in df_pct.columns:
        df_pct = df_pct.drop(columns=['total_new_users'])

    # CrÃ©er la figure Plotly
    fig = go.Figure()

    # CrÃ©er une palette de couleurs distinctes pour chaque cohorte
    colormap = cm.get_cmap('tab20c', len(df_pct))

    # Tracer chaque cohorte en ligne
    for i, (cohorte, row) in enumerate(df_pct.iterrows()):
        # Garder uniquement les colonnes non-NaN
        valid_values = row.dropna()
        if valid_values.empty:
            continue
        # GÃ©nÃ©rer une couleur pour cette cohorte
        rgba = colormap(i / len(df_pct))
        color = f"rgba({int(rgba[0]*255)},{int(rgba[1]*255)},{int(rgba[2]*255)},{rgba[3]})"
        
        fig.add_trace(go.Scatter(
            x=list(valid_values.index),
            y=list(valid_values.values),
            mode="lines",
            name=f"Cohorte {cohorte.strftime('%Y-%m-%d')}",
            line=dict(color=color, width=2)
        ))

    # Ajouter une courbe moyenne sur toutes les cohortes
    average_curve = df_pct.mean(axis=0, skipna=True)
    fig.add_trace(go.Scatter(
        x=list(average_curve.index),
        y=list(average_curve.values),
        mode="lines",
        name="Moyenne",
        line=dict(color="black", width=3)
    ))

    # Mise en forme du graphique
    fig.update_layout(
        title="Ã‰volution du pourcentage d'utilisateurs par cohorte (hebdomadaire)",
        xaxis_title="Semaine aprÃ¨s le premier achat (ex: +0, +1, +2, ...)",
        yaxis_title="Pourcentage de rÃ©tention (%)",
        template="plotly_white",
        xaxis=dict(
            tickmode='array',
            tickvals=[f"+{i}" for i in range(len(average_curve))]
        )
    )

    # Afficher le graphique dans Streamlit
    st.plotly_chart(fig)

    # ========================
    # ğŸ“… Cohortes par MOIS (nouveaux utilisateurs ayant payÃ© ce mois-lÃ )
    # ========================
    # DÃ©finir le filtre de base pour tous les paiements dans la pÃ©riode et pour le magasin
    # ----------------------------
    # 1) Construction des pipelines
    # ---------------------------

    # Pipeline pour rÃ©cupÃ©rer les nouveaux utilisateurs par mois
    if selected_payment_method == "Tous":
        pipeline_new_users = [
            {"$unwind": "$receipt"},
            {"$match": base_filter},
            {"$sort": {"receipt.paidAt": 1}},
            {"$group": {
                "_id": "$_id",
                "firstPaidAt": {"$first": "$receipt.paidAt"}
            }},
            {"$group": {
                "_id": {
                    "year": {"$year": "$firstPaidAt"},
                    "month": {"$month": "$firstPaidAt"}
                },
                "new_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_new_users": {"$size": "$new_users"},
                "new_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.month": 1}}
        ]
    else:
        variants = payment_variants.get(selected_payment_method, [selected_payment_method])
        pipeline_new_users = [
            # Ã‰tape 1 : SÃ©lectionner les utilisateurs ayant utilisÃ© le mode choisi
            {"$unwind": "$receipt"},
            {"$match": {
                "receipt.isPaid": True,
                "receipt.storeId": store_filter,
                "receipt.paymentMethod": {"$in": variants}
            }},
            {"$group": {"_id": "$_id"}},

            # Ã‰tape 2 : Trouver le premier paiement (toutes mÃ©thodes confondues)
            {"$lookup": {
                "from": "usertests",
                "localField": "_id",
                "foreignField": "_id",
                "as": "user_data"
            }},
            {"$unwind": "$user_data"},
            {"$unwind": "$user_data.receipt"},
            {"$match": {
                "user_data.receipt.isPaid": True,
                "user_data.receipt.storeId": store_filter
            }},
            {"$sort": {"user_data.receipt.paidAt": 1}},
            {"$group": {
                "_id": "$_id",
                "firstPaidAt": {"$first": "$user_data.receipt.paidAt"}
            }},
            {"$match": {
                "firstPaidAt": {"$gte": date_start, "$lte": date_end}
            }},
            {"$group": {
                "_id": {
                    "year": {"$year": "$firstPaidAt"},
                    "month": {"$month": "$firstPaidAt"}
                },
                "new_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_new_users": {"$size": "$new_users"},
                "new_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.month": 1}}
        ]


    # Pipeline pour rÃ©cupÃ©rer les utilisateurs actifs par mois
    if selected_payment_method == "Tous":
        pipeline_active_users = [
            {"$unwind": "$receipt"},
            {"$match": {**base_filter, "_id": {"$nin": testers_to_exclude}}},
            {"$addFields": {
                "paymentYear": {"$year": "$receipt.paidAt"},
                "paymentMonth": {"$month": "$receipt.paidAt"}
            }},
            {"$group": {
                "_id": {"year": "$paymentYear", "month": "$paymentMonth"},
                "active_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_active_users": {"$size": "$active_users"},
                "active_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.month": 1}}
        ]
    else:
        pipeline_active_users = [
            {"$unwind": "$receipt"},
            {"$match": {
                "receipt.isPaid": True,
                "receipt.storeId": store_filter,
                "receipt.paidAt": {"$gte": date_start, "$lte": date_end},
                "receipt.paymentMethod": {"$in": variants},  # Utiliser la mÃªme logique que pour les nouveaux utilisateurs
                "_id": {"$nin": testers_to_exclude}
            }},
            {"$addFields": {
                "paymentYear": {"$year": "$receipt.paidAt"},
                "paymentMonth": {"$month": "$receipt.paidAt"}
            }},
            {"$group": {
                "_id": {"year": "$paymentYear", "month": "$paymentMonth"},
                "active_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_active_users": {"$size": "$active_users"},
                "active_users": 1
            }},
            {"$sort": {"_id.year": 1, "_id.month": 1}}
        ]

    # ----------------------------
    # 2) ExÃ©cution des pipelines
    # ----------------------------
    cursor_new_users = users_collection.aggregate(pipeline_new_users)
    cursor_active_users = users_collection.aggregate(pipeline_active_users)

    data_new_users = list(cursor_new_users)
    data_active_users = list(cursor_active_users)

    if not data_new_users or not data_active_users:
        st.error("âŒ Aucune donnÃ©e trouvÃ©e ! VÃ©rifiez la structure de votre base MongoDB.")
        st.stop()

    # ----------------------------
    # 3) Construction des DataFrames
    # ----------------------------
    df_new_users = pd.DataFrame(data_new_users)
    df_active_users = pd.DataFrame(data_active_users)

    # Extraire l'annÃ©e et le mois depuis l'_id
    df_new_users['year'] = df_new_users['_id'].apply(lambda x: x['year'])
    df_new_users['month'] = df_new_users['_id'].apply(lambda x: x['month'])
    df_active_users['year'] = df_active_users['_id'].apply(lambda x: x['year'])
    df_active_users['month'] = df_active_users['_id'].apply(lambda x: x['month'])

    # CrÃ©er la colonne "month_start"
    df_new_users['month_start'] = df_new_users.apply(lambda x: datetime(x['year'], x['month'], 1), axis=1)
    df_active_users['month_start'] = df_active_users.apply(lambda x: datetime(x['year'], x['month'], 1), axis=1)

    # Convertir les ensembles d'IDs en chaÃ®nes
    df_new_users['new_users'] = df_new_users['new_users'].apply(lambda users: set(str(u) for u in users) if users else set())
    df_active_users['active_users'] = df_active_users['active_users'].apply(lambda users: set(str(u) for u in users) if users else set())

    # Trier et indexer
    df_new_users = df_new_users.sort_values(by='month_start').set_index('month_start')
    df_active_users = df_active_users.sort_values(by='month_start').set_index('month_start')

    # ----------------------------
    # 4) Calcul de la rÃ©tention mensuelle
    # ----------------------------
    monthly_retention = {}
    for index, row in df_new_users.iterrows():
        new_user_set = row['new_users']
        monthly_retention[index] = {"+0": row["total_new_users"]}

        if not new_user_set:
            continue

        # Pour chaque mois >= la cohorte, on vÃ©rifie combien sont toujours actifs
        future_months = df_active_users.loc[df_active_users.index >= index]
        for month_diff, (future_index, future_row) in enumerate(future_months.iterrows()):
            future_users = future_row['active_users']
            retained_users = len(new_user_set.intersection(future_users)) if isinstance(future_users, set) else 0
            monthly_retention[index][f"+{month_diff}"] = retained_users

    # On convertit ce dictionnaire en DataFrame
    df_monthly_retention = pd.DataFrame.from_dict(monthly_retention, orient='index')

    # âœ… Correction : Forcer la colonne "+0" Ã  Ãªtre identique Ã  "total_new_users"
    df_monthly_retention["+0"] = df_new_users["total_new_users"]

    # Fusionner avec df_new_users pour rÃ©cupÃ©rer total_new_users
    df_final = df_new_users[['total_new_users']].merge(
        df_monthly_retention, left_index=True, right_index=True, how='left'
    )


    # ----------------------------
    # 5) Afficher tous les mois de la plage, mÃªme s'ils sont Ã  0
    # ----------------------------
    # a) GÃ©nÃ©rer la liste complÃ¨te des mois (freq='MS' => dÃ©but de mois)
    all_months_range = pd.date_range(start=date_start, end=datetime.now(), freq='MS')
    all_months_df = pd.DataFrame(index=all_months_range)
    all_months_df['total_new_users'] = 0  # Valeur par dÃ©faut

    # b) Fusionner pour forcer l'affichage de tous les mois
    df_merged = all_months_df.merge(df_final, left_index=True, right_index=True, how='left', suffixes=('', '_old'))

    # RÃ©cupÃ©rer la bonne valeur de total_new_users
    if 'total_new_users_old' in df_merged.columns:
        df_merged['total_new_users'] = df_merged['total_new_users_old'].fillna(df_merged['total_new_users'])
        df_merged.drop(columns=['total_new_users_old'], inplace=True)

    df_final = df_merged

    # c) Calcul du global_max (plus grand dÃ©calage possible entre la cohorte et le mois courant)
    current_date = datetime.now()
    current_month_start = datetime(current_date.year, current_date.month, 1)
    global_max = 0
    for cohort_date in df_final.index:
        offset = (current_month_start.year - cohort_date.year) * 12 + (current_month_start.month - cohort_date.month)
        if offset > global_max:
            global_max = offset

    # d) Ajouter les colonnes +0, +1, ..., +global_max si elles n'existent pas
    for offset in range(global_max + 1):
        col_name = f"+{offset}"
        if col_name not in df_final.columns:
            df_final[col_name] = None

    # e) Remplir les valeurs 0 pour les mois passÃ©s ou Ã©gaux, None pour le futur
    for index, row in df_final.iterrows():
        for offset in range(global_max + 1):
            col_name = f"+{offset}"
            future_month = index + pd.DateOffset(months=offset)
            if future_month <= current_month_start:
                if pd.isna(row[col_name]):
                    df_final.at[index, col_name] = 0
            else:
                df_final.at[index, col_name] = None

    # ----------------------------
    # 6) Affichage des cohortes mensuelles (valeurs numÃ©riques)
    # ----------------------------
    st.title("Partie RÃ©tention - Analyse Mensuelle")
    st.header("ğŸ“… Tableau des cohortes mensuelles")
    st.subheader("ğŸ“Š Cohortes mensuelles (valeurs numÃ©riques)")
    st.dataframe(df_final)

    # ----------------------------
    # 7) Calcul des pourcentages
    # ----------------------------
    df_percentage = df_final.copy()
    df_percentage_calcul = df_final.copy()

    for col in df_percentage.columns:
        if col.startswith("+"):
            if col == "+0":
                df_percentage[col] = df_percentage_calcul["+0"].apply(lambda x: 100 if x > 0 else 0)
            else:
                mask = (df_percentage_calcul["+0"] > 0) & (df_percentage_calcul[col].notna())
                df_percentage.loc[mask, col] = (
                    df_percentage_calcul.loc[mask, col] / df_percentage_calcul.loc[mask, "+0"] * 100
                ).round(1)

    def apply_red_gradient_with_future(val):
        if pd.isna(val):
            return 'background-color: #f0f0f0; color: #f0f0f0;'
        elif pd.notna(val):
            intensity = int(255 * ((1 - val / 100) ** 3))
            return f'background-color: rgba(255, {intensity}, {intensity}, 1); color: black;'
        return ''

    st.subheader("ğŸ“Š Cohortes mensuelles (%)")
    st.dataframe(
        df_percentage.style.applymap(apply_red_gradient_with_future, subset=[c for c in df_percentage.columns if c.startswith("+")])
    )

    # ----------------------------
    # 8) (Optionnel) Graphique de rÃ©tention mensuelle
    # ----------------------------
    # Supprimer "total_new_users" avant le tracÃ©
    df_plot = df_percentage.drop(columns=["total_new_users"]) if "total_new_users" in df_percentage.columns else df_percentage.copy()

    fig = go.Figure()
    colormap = cm.get_cmap('tab20c', len(df_plot))

    for i, (idx, row) in enumerate(df_plot.iterrows()):
        valid_values = row.dropna()
        if "+0" not in valid_values.index:
            continue
        rgba = colormap(i / len(df_plot))
        color = f'rgba({int(rgba[0]*255)},{int(rgba[1]*255)},{int(rgba[2]*255)},{rgba[3]})'
        fig.add_trace(go.Scatter(
            x=valid_values.index,
            y=valid_values.values,
            mode='lines',
            name=f"Cohorte {idx.strftime('%Y-%m-%d')}",
            line=dict(width=2, color=color),
            hoverinfo='x+y',
            opacity=0.8
        ))

    # Courbe moyenne
    average_curve = df_plot.mean(axis=0, skipna=True)
    fig.add_trace(go.Scatter(
        x=average_curve.index,
        y=average_curve.values,
        mode='lines',
        name='Moyenne par +x',
        line=dict(width=3, color='black'),
        opacity=1.0
    ))

    fig.update_layout(
        title="ğŸ“Š RÃ©tention des utilisateurs par mois (%)",
        xaxis_title="Mois aprÃ¨s premier achat",
        yaxis_title="Pourcentage de rÃ©tention",
        template="plotly_white",
        xaxis=dict(
            tickmode='array',
            tickvals=[f'+{i}' for i in range(len(average_curve))]
        ),
        yaxis=dict(
            tickformat=".1f",
            range=[0, 110]
        )
    )

    st.header("ğŸ“ˆ Ã‰volution du pourcentage d'utilisateurs par cohorte (mensuelle)")
    st.plotly_chart(fig)

    # ========================
    # Layer Cake Chart
    # ========================
    st.title("ğŸ° Partie Layer Cake")

    # VÃ©rifier que df_numeric_week existe et n'est pas vide
    if 'df_numeric_week' not in locals() or df_numeric_week.empty:
        st.warning("âŒ Aucune donnÃ©e de rÃ©tention hebdomadaire disponible pour gÃ©nÃ©rer le Layer Cake.")
        st.stop()

    # Copier df_numeric_week et remplacer NaN par 0
    df_layer_cake = df_numeric_week.copy().fillna(0)

    # Supprimer la colonne "total_new_users" si elle existe
    if "total_new_users" in df_layer_cake.columns:
        df_layer_cake = df_layer_cake.drop(columns=["total_new_users"])

    # Conserver uniquement les colonnes de rÃ©tention (celles qui commencent par "+")
    retention_cols = [col for col in df_layer_cake.columns if col.startswith("+")]
    # Assurer un ordre croissant, par exemple "+0", "+1", "+2", ...
    retention_cols = sorted(retention_cols, key=lambda c: int(c.replace("+", "")))
    df_layer_cake = df_layer_cake[retention_cols]

    # On suppose que l'index (les cohortes) est dÃ©jÃ  chronologique (du plus ancien au plus rÃ©cent)
    df_layer_cake.sort_index(ascending=True, inplace=True)

    num_weeks = len(retention_cols)
    x_axis = np.arange(num_weeks)  # Axe x : [0, 1, 2, ..., num_weeks-1]

    # Initialiser la figure Plotly et la palette de couleurs
    fig = go.Figure()
    num_cohorts = len(df_layer_cake)
    colormap = cm.get_cmap('tab20c', num_cohorts)

    # Parcourir chaque cohorte (du plus ancien au plus rÃ©cent)
    for i, (cohort_date, row) in enumerate(df_layer_cake.iterrows()):
        # Extraire les valeurs de rÃ©tention de la cohorte
        cohort_values = np.array(row.tolist(), dtype=float)
        
        # CrÃ©er une sÃ©rie dÃ©calÃ©e : i positions initiales seront None pour ne pas afficher de valeurs avant le dÃ©but
        shifted = [None] * i + list(cohort_values[:num_weeks - i])
        
        rgba = colormap(i / num_cohorts)
        color = f"rgba({int(rgba[0]*255)},{int(rgba[1]*255)},{int(rgba[2]*255)},{rgba[3]})"
        
        fig.add_trace(go.Scatter(
            x=x_axis,
            y=shifted,
            mode='lines',
            stackgroup='one',  # Empilement automatique avec Plotly
            name=f"Cohorte {cohort_date.strftime('%Y-%m-%d')}",
            line=dict(color=color)
        ))

    # Configurer l'axe x pour afficher "+0", "+1", ... etc.
    fig.update_xaxes(
        tickmode='array',
        tickvals=list(x_axis),
        ticktext=[f"+{i}" for i in x_axis]
    )

    # Mettre Ã  jour la mise en page pour isoler la trace cliquÃ©e dans la lÃ©gende
    fig.update_layout(
        title="ğŸ“Š Layer Cake Chart - RÃ©tention des utilisateurs",
        xaxis_title="Semaines aprÃ¨s premier achat",
        yaxis_title="Nombre d'utilisateurs cumulÃ©s",
        template="plotly_white",
        legend_title="Cohortes hebdomadaires",
    )

    st.plotly_chart(fig)


# ========================
# Acquisition des utilisateurs
# ========================
if page == "Acquisition":

    # ğŸ“Œ Pipeline MongoDB pour rÃ©cupÃ©rer le nombre d'utilisateurs crÃ©Ã©s par semaine
    pipeline_new_users_per_week = [
        {"$match": {
            "createdAt": {"$gte": date_start, "$lte": date_end}
        }},
        {"$group": {
            "_id": {
                "year": {"$isoWeekYear": "$createdAt"},
                "week": {"$isoWeek": "$createdAt"}
            },
            "new_users": {"$sum": 1}
        }},
        {"$sort": {"_id.year": 1, "_id.week": 1}}
    ]

    # ğŸ“Œ ExÃ©cuter la requÃªte MongoDB
    cursor_new_users_per_week = users_collection.aggregate(pipeline_new_users_per_week)
    data_new_users_per_week = list(cursor_new_users_per_week)

    # ğŸ“Œ VÃ©rification des donnÃ©es
    if not data_new_users_per_week:
        st.error("âŒ Aucune donnÃ©e trouvÃ©e pour les nouveaux utilisateurs par semaine !")
        st.stop()

    # ğŸ“Œ Transformation en DataFrame
    df_new_users_per_week = pd.DataFrame(data_new_users_per_week)

    # ğŸ“Œ Extraction des annÃ©es et semaines
    df_new_users_per_week['year'] = df_new_users_per_week['_id'].apply(lambda x: x['year'])
    df_new_users_per_week['week'] = df_new_users_per_week['_id'].apply(lambda x: x['week'])

    # ğŸ“Œ GÃ©nÃ©rer la colonne du dÃ©but de semaine
    df_new_users_per_week['week_start'] = df_new_users_per_week.apply(
        lambda x: datetime.fromisocalendar(x['year'], x['week'], 1), axis=1
    )

    # ğŸ“Œ Trier et indexer les donnÃ©es
    df_new_users_per_week = df_new_users_per_week.sort_values(by='week_start').set_index('week_start')

    st.title("Partie Acquisition")
    # ğŸ“Œ Affichage du tableau des nouveaux utilisateurs par semaine
    st.subheader("ğŸ“… Nombre de nouveaux utilisateurs par semaine")
    st.dataframe(df_new_users_per_week['new_users'])

    # ğŸ“Œ CrÃ©er une courbe interactive avec Plotly
    fig = px.line(df_new_users_per_week,
                x=df_new_users_per_week.index,
                y="new_users",
                title="ğŸ“ˆ Ã‰volution des nouveaux utilisateurs par semaine",
                labels={"week_start": "Semaine", "new_users": "Nouveaux utilisateurs"},
                markers=True)
    st.subheader("ğŸ“ˆ Ã‰volution des nouveaux utilisateurs par semaine")
    st.plotly_chart(fig)

    # ========================
    # Weekly Active Users 
    # ========================

if page == "Active Users":
        # ğŸ”¹ DÃ©finir le filtre de base
        match_filter = {
            "receipt.isPaid": True,
            "receipt.paidAt": {"$gte": date_start, "$lte": date_end},
            "receipt.storeId": store_filter
        }

        # ğŸ”¹ Ajouter un filtre pour le mode de paiement si un mode spÃ©cifique est sÃ©lectionnÃ©
        if selected_payment_method != "Tous":
            variants = payment_variants.get(selected_payment_method, [selected_payment_method])
            match_filter["receipt.paymentMethod"] = {"$in": variants}

        # ========================
        # ğŸ“Œ Pipeline pour utilisateurs uniques par SEMAINE
        # ========================
        pipeline_unique_users_per_week = [
            {"$unwind": "$receipt"},
            {"$match": match_filter},
            {"$group": {
                "_id": {
                    "year": {"$isoWeekYear": "$receipt.paidAt"},
                    "week": {"$isoWeek": "$receipt.paidAt"}
                },
                "unique_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_unique_users": {"$size": "$unique_users"}
            }},
            {"$sort": {"_id.year": 1, "_id.week": 1}}
        ]

        # ğŸ”¹ ExÃ©cuter la requÃªte MongoDB
        cursor_unique_users_per_week = users_collection.aggregate(pipeline_unique_users_per_week)
        data_unique_users_per_week = list(cursor_unique_users_per_week)

        # ğŸ”¹ VÃ©rification des donnÃ©es
        if not data_unique_users_per_week:
            st.error("âŒ Aucune donnÃ©e trouvÃ©e pour les utilisateurs uniques par semaine !")
            st.stop()

        # ğŸ”¹ Transformation en DataFrame
        df_unique_users_per_week = pd.DataFrame(data_unique_users_per_week)

        # ğŸ”¹ Extraction des annÃ©es et semaines
        df_unique_users_per_week['year'] = df_unique_users_per_week['_id'].apply(lambda x: x['year'])
        df_unique_users_per_week['week'] = df_unique_users_per_week['_id'].apply(lambda x: x['week'])

        # ğŸ”¹ GÃ©nÃ©rer la colonne du dÃ©but de semaine
        df_unique_users_per_week['week_start'] = df_unique_users_per_week.apply(
            lambda x: datetime.fromisocalendar(x['year'], x['week'], 1), axis=1
        )

        # ğŸ”¹ Trier et indexer les donnÃ©es
        df_unique_users_per_week = df_unique_users_per_week.sort_values(by='week_start').set_index('week_start')

        # ğŸ”¹ GÃ©nÃ©rer toutes les semaines
        all_weeks = pd.date_range(start=df_unique_users_per_week.index.min(), 
                                end=df_unique_users_per_week.index.max(), freq='W-MON')
        df_all_weeks_unique_users = pd.DataFrame(index=all_weeks)
        df_all_weeks_unique_users['total_unique_users'] = 0

        # ğŸ”¹ Mettre Ã  jour les valeurs des semaines
        df_all_weeks_unique_users.update(df_unique_users_per_week)

        # ğŸ”¹ Affichage
        st.title("Partie Weekly Active Users")
        st.subheader("ğŸ“Š Tableau utilisateurs uniques par semaine")
        st.dataframe(df_all_weeks_unique_users)

        # ğŸ”¹ Graphique
        fig = px.line(df_all_weeks_unique_users, 
                    x=df_all_weeks_unique_users.index, 
                    y="total_unique_users", 
                    title="ğŸ“ˆ Ã‰volution des utilisateurs uniques par semaine",
                    labels={"week_start": "Semaine", "total_unique_users": "Utilisateurs uniques"},
                    markers=True)
        st.subheader("ğŸ“ˆ Ã‰volution des utilisateurs uniques par semaine")
        st.plotly_chart(fig)

        # ========================
        # ğŸ“Œ Pipeline pour utilisateurs uniques par MOIS
        # ========================
        pipeline_unique_users_per_month = [
            {"$unwind": "$receipt"},
            {"$match": match_filter},
            {"$group": {
                "_id": {
                    "year": {"$year": "$receipt.paidAt"},
                    "month": {"$month": "$receipt.paidAt"}
                },
                "unique_users": {"$addToSet": "$_id"}
            }},
            {"$project": {
                "_id": 1,
                "total_unique_users": {"$size": "$unique_users"}
            }},
            {"$sort": {"_id.year": 1, "_id.month": 1}}
        ]

        # ğŸ”¹ ExÃ©cuter la requÃªte MongoDB
        cursor_unique_users_per_month = users_collection.aggregate(pipeline_unique_users_per_month)
        data_unique_users_per_month = list(cursor_unique_users_per_month)

        # ğŸ”¹ VÃ©rification des donnÃ©es
        if not data_unique_users_per_month:
            st.error("âŒ Aucune donnÃ©e trouvÃ©e pour les utilisateurs uniques par mois !")
            st.stop()

        # ğŸ”¹ Transformation en DataFrame
        df_unique_users_per_month = pd.DataFrame(data_unique_users_per_month)

        # ğŸ”¹ Extraction des annÃ©es et mois
        df_unique_users_per_month['year'] = df_unique_users_per_month['_id'].apply(lambda x: x['year'])
        df_unique_users_per_month['month'] = df_unique_users_per_month['_id'].apply(lambda x: x['month'])

        # ğŸ”¹ GÃ©nÃ©rer la colonne du dÃ©but de mois
        df_unique_users_per_month['month_start'] = df_unique_users_per_month.apply(
            lambda x: datetime(x['year'], x['month'], 1), axis=1
        )

        # ğŸ”¹ Trier et indexer les donnÃ©es
        df_unique_users_per_month = df_unique_users_per_month.sort_values(by='month_start').set_index('month_start')

        # ğŸ”¹ GÃ©nÃ©rer toutes les mois
        all_months = pd.date_range(start=df_unique_users_per_month.index.min(), 
                                end=df_unique_users_per_month.index.max(), 
                                freq='MS')
        df_all_months_unique_users = pd.DataFrame(index=all_months)
        df_all_months_unique_users['total_unique_users'] = 0

        # ğŸ”¹ Mettre Ã  jour les valeurs des mois
        df_all_months_unique_users.update(df_unique_users_per_month)

        # ğŸ”¹ Affichage
        st.title("Partie Monthly Active Users")
        st.subheader("ğŸ“Š Tableau utilisateurs uniques par mois")
        st.dataframe(df_all_months_unique_users)

        # ğŸ”¹ Graphique
        fig = px.line(df_all_months_unique_users, 
                    x=df_all_months_unique_users.index, 
                    y="total_unique_users", 
                    title="ğŸ“ˆ Ã‰volution des utilisateurs uniques par mois",
                    labels={"month_start": "Mois", "total_unique_users": "Utilisateurs uniques"},
                    markers=True)
        st.subheader("ğŸ“ˆ Ã‰volution des utilisateurs uniques par mois")
        st.plotly_chart(fig)


# ========================
# Bug Report
# ========================

if page == "Bug Report":
    st.title("Partie Bug Report")
    # ğŸ“Œ DÃ©finition de la semaine actuelle (du lundi au dimanche)
    today = datetime.now()
    current_week_start = (today - timedelta(days=today.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)
    current_week_end = current_week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)

    # ğŸ“Œ RequÃªte MongoDB pour rÃ©cupÃ©rer les paniers abandonnÃ©s de la semaine en cours
    non_finalized_carts = list(orders_collection.find({
        'isPaid': False,
        'createdAt': {'$gte': current_week_start, '$lte': current_week_end},
        'scanItems': {'$exists': True, '$ne': []}  
    }))

    # ğŸ“Œ Nombre total de paniers abandonnÃ©s
    total_non_finalized = len(non_finalized_carts)

    # ğŸ“Œ Mapping des magasins
    store_mapping = {
        "65e6388eb6667e3400b5b8d8": "SupermarchÃ© Match",
        "65d3631ff2cd066ab75434fa": "IntermarchÃ© Saint Julien",
        "662bb3234c362c6e79e27020": "Netto Troyes",
        "64e48f4697303382f745cb11": "Carrefour Contact BuchÃ¨res",
        "65ce4e565a9ffc7e5fe298bb": "Carrefour Market Romilly",
        "65b8bde65a0ef81ff30473bf": "Jils Food",
        "67a8fef293a9fcb4dec991b4": "IntermarchÃ© EXPRESS Clamart"
    }

    # ğŸ“Œ Comptage des paniers abandonnÃ©s par magasin
    non_finalized_counts = defaultdict(int)
    for cart in non_finalized_carts:
        store_id = cart.get('storeId')
        store_name = store_mapping.get(str(store_id), "Inconnu") 
        non_finalized_counts[store_name] += 1

    # ğŸ“Œ Conversion en DataFrame et tri des rÃ©sultats
    non_finalized_df = pd.DataFrame(list(non_finalized_counts.items()), columns=['Magasin', 'Paniers AbandonnÃ©s'])
    non_finalized_df = non_finalized_df.sort_values(by='Paniers AbandonnÃ©s', ascending=False)

    # ğŸ“Œ Affichage des rÃ©sultats
    st.subheader("ğŸ›’ Paniers abandonnÃ©s de la semaine")
    st.write(f"Nombre total de paniers abandonnÃ©s : {total_non_finalized}")
    st.write(non_finalized_df)